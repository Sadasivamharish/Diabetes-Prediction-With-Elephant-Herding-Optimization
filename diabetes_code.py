# -*- coding: utf-8 -*-
"""Diabetes Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FS0WIpR7V6xr-ZuuvzEkAucOf3arX96F
"""

#Reading the Dataset
import pandas as pd
df = pd.read_csv('iraqi-diabetes-dataset.csv')
df.head(1000)

import pandas as pd
import matplotlib.pyplot as plt

data = pd.read_csv('iraqi-diabetes-dataset.csv')

# Selecting relevant columns
selected_columns = ['AGE', 'Urea', 'Cr', 'HbA1c', 'Chol', 'TG', 'HDL', 'LDL', 'VLDL', 'BMI', 'CLASS']

# Plotting the population distributions for each parameter
for col in selected_columns[:-1]:  # Exclude 'CLASS' for obvious reasons
    plt.figure(figsize=(8, 6))
    plt.hist([data[data['CLASS'] == 'Y'][col],
              data[data['CLASS'] == 'N'][col],
              data[data['CLASS'] == 'P'][col]],
             bins=20, alpha=0.7, label=['Y', 'N', 'P'])
    plt.title(f'Population Distribution of {col}')
    plt.xlabel(col)
    plt.ylabel('Frequency')
    plt.legend()
    plt.show()

#Building the ANN Model (Without EHO)
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense
from sklearn.preprocessing import label_binarize

# Load the dataset
df = pd.read_csv('iraqi-diabetes-dataset.csv')

# Preprocess the data
X = df['HbA1c']
X = np.array(X).reshape(-1, 1)

# Create the target variable
y = np.where((X >= 4.0) & (X <= 5.7), 0, np.where((X > 5.7) & (X <= 6.4), 1, np.where(X > 6.4, 2, 3)))

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Reshape y_train and y_test to (-1,)
y_train = y_train.reshape(-1,)
y_test = y_test.reshape(-1,)

# One-hot encode the target variables
y_train_one_hot = np.eye(7)[y_train.astype(int)]
y_test_one_hot = np.eye(7)[y_test.astype(int)]

# Normalize the data
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define the model
model = Sequential()
model.add(Dense(10, activation='relu', input_shape=(1,)))
model.add(Dense(7, activation='softmax'))

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train_one_hot, epochs=100)

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test_one_hot)
print('Loss:', loss)
print('Accuracy:', accuracy)

# Predict the classes of the patients
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)


# Number of patients in each category
non_diabetic = np.sum(y_pred_classes == 0)
pre_diabetic = np.sum(y_pred_classes == 1)
diabetic = np.sum(y_pred_classes == 2)


# Print the results
print('Number of patients in each category:')
print('Non Diabetic:', non_diabetic)
print('Pre Diabetic:', pre_diabetic)
print('Diabetic:', diabetic)

# Confusion Matrix
import seaborn as sns

sns.heatmap(y_pred, cmap='coolwarm')
plt.xlabel('Predicted Class')
plt.ylabel('Actual Class')
plt.title('Confusion Matrix')
plt.show()

# Code for Distance Between Matriarch and Clan Updating Operator
import pandas as pd
import matplotlib.pyplot as plt
from scipy.spatial import distance
from sklearn.metrics import confusion_matrix
import seaborn as sns

# Load the dataset
df = pd.read_csv('iraqi-diabetes-dataset.csv')

# Identify diabetic and pre-diabetic patients
df['Patient_Class'] = pd.cut(df['HbA1c'], bins=[0, 5.6, 6.4, df['HbA1c'].max()], labels=['Non Diabetic', 'Pre Diabetic', 'Diabetic'])

# Filter out the diabetic patients
diabetic_df = df[df['Patient_Class'] == 'Diabetic']

# Identify the matriarch operator
matriarch_operator = diabetic_df[diabetic_df['HbA1c'] == diabetic_df['HbA1c'].min()]

# Calculate the distance between diabetic and pre-diabetic patients
pre_diabetic_df = df[df['Patient_Class'] == 'Pre Diabetic']
distances = distance.cdist(diabetic_df[['HbA1c']], pre_diabetic_df[['HbA1c']], 'euclidean')

print("Matriarch Operator: ", matriarch_operator)
print("Distances: ", distances)

# Plotting the distances
plt.figure(figsize=(10, 6))
sns.histplot(distances, bins=30, kde=False)
plt.title('Distribution of Distances between Diabetic and Pre-Diabetic Patients')
plt.xlabel('Distance')
plt.ylabel('Frequency')
plt.show()

# Convergence history
convergence = [np.linalg.norm(distances[i]-distances[i-1]) for i in range(1, len(distances))]
plt.figure(figsize=(10, 6))
plt.plot(convergence)
plt.title('Convergence History')
plt.xlabel('Iteration')
plt.ylabel('Distance')
plt.show()

#Code for Seperating Operator
import pandas as pd
import matplotlib.pyplot as plt
from scipy.spatial import distance
import seaborn as sns

# Load the dataset
df = pd.read_csv('iraqi-diabetes-dataset.csv')

# Identify diabetic and non-diabetic patients
df['Patient_Class'] = pd.cut(df['HbA1c'], bins=[0, 5.6, 6.4, df['HbA1c'].max()], labels=['Non Diabetic', 'Pre Diabetic', 'Diabetic'])

# Filter out the non-diabetic patients
non_diabetic_df = df[df['Patient_Class'] == 'Non Diabetic']

# Identify the separating operator
separating_operator = non_diabetic_df[non_diabetic_df['HbA1c'] == non_diabetic_df['HbA1c'].min()]

# Calculate the distance between diabetic and non-diabetic patients
diabetic_df = df[df['Patient_Class'] == 'Diabetic']
distances = distance.cdist(diabetic_df[['HbA1c']], non_diabetic_df[['HbA1c']], 'euclidean')

print("Separating Operator: ", separating_operator)
print("Distances: ", distances)

# Plotting the distances
plt.figure(figsize=(10, 6))
sns.histplot(distances, bins=30, kde=False)
plt.title('Distribution of Distances between Diabetic and Non-Diabetic Patients')
plt.xlabel('Distance')
plt.ylabel('Frequency')
plt.show()

# Convergence history
convergence = [np.linalg.norm(distances[i]-distances[i-1]) for i in range(1, len(distances))]
plt.figure(figsize=(10, 6))
plt.plot(convergence)
plt.title('Convergence History')
plt.xlabel('Iteration')
plt.ylabel('Distance')
plt.show()

#Optimization using Elephant Herding Algorithm
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Load the diabetes dataset
df = pd.read_csv('iraqi-diabetes-dataset.csv')

# Define the fitness function
def fitness(x):
    return np.array([np.sum(np.square(xi - df[df['HbA1c'] > 6.4]['HbA1c'].values)) for xi in x])
# Define the matriarch operator
def matriarch_operator(elephants):
  matriarch = elephants[np.random.randint(0, len(elephants))]
  return matriarch

# Define the clan updating operator
def clan_updating_operator(elephants, matriarch):
  for i in range(len(elephants)):
    if not np.array_equal(elephants[i], matriarch):
      elephants[i] += np.random.rand() * (matriarch - elephants[i])
  return elephants

# Define the separating operator
def separating_operator(elephants, matriarch):
  for i in range(len(elephants)):
    if not np.array_equal(elephants[i], matriarch):
      elephants[i] += np.random.rand() * (elephants[i] - matriarch)
  return elephants

# Initialize the elephant population
elephants = np.random.rand(100, 1)

# Set the maximum number of iterations
max_iterations = 100

# Initialize the convergence history
convergence_history = []

# Start the optimization loop
for i in range(max_iterations):

  # Calculate the fitness of each elephant
  fitness_values = fitness(elephants)

  # Find the matriarch elephant
  matriarch = matriarch_operator(elephants)

  # Update the elephant population using the clan updating operator
  elephants = clan_updating_operator(elephants, matriarch)

  # Separate the non-diabetic elephants from the diabetic elephants
  elephants = separating_operator(elephants, matriarch)

  # Add the current minimum fitness value to the convergence history
  convergence_history.append(fitness_values.min())

# Calculate the optimal solution
optimal_solution = elephants[np.argmin(fitness_values)]

# Print the results
print('Optimal Solution:', optimal_solution)
print('Pre Diabetic Mean Fitness: {:.2f} +/- {:.2f}'.format(optimal_solution[0], np.std(df[(df['HbA1c'] >= 5.7) & (df['HbA1c'] < 6.4)]['HbA1c'])))
print('Diabetic Mean Fitness: {:.2f} +/- {:.2f}'.format(optimal_solution[0], np.std(df[df['HbA1c'] > 6.4]['HbA1c'])))
print('Number of iterations:', i + 1)


# Plot the convergence history
plt.plot(convergence_history)
plt.xlabel('Iteration')
plt.ylabel('Fitness Value')
plt.title('Convergence History')
plt.show()



import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score
import seaborn as sns

# Load the diabetes dataset
df = pd.read_csv('iraqi-diabetes-dataset.csv')

# Assuming 'HbA1c' is your target variable
X = df['HbA1c'].values.reshape(-1, 1) # Use only the 'HbA1c' column as input
y = df['HbA1c'].values # Use 'HbA1c' column as output

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train the ANN with optimized weights
model = Sequential()
model.add(Dense(32, activation='relu', input_dim=1)) # Add a hidden layer with 32 neurons and relu activation function, and an input layer with 1 neuron
model.add(Dense(1)) # Add an output layer with 1 neuron

# Get current weights of the first layer
weights, biases = model.layers[0].get_weights()

# Create new weights and biases with the same shape as the current ones
new_weights = np.full_like(weights, optimal_solution)
new_biases = np.full_like(biases, optimal_solution)

# Set new weights and biases
model.layers[0].set_weights([new_weights, new_biases])

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error') # Use adam optimizer and mean squared error as the loss function

# Convert input data to float
X_train_float = X_train.astype(float)
y_train_float = y_train.astype(float)

# Train the model using X_train and y_train
model.fit(X_train_float, y_train_float, epochs=100, batch_size=32)

# Convert test data to float
X_test_float = X_test.astype(float)
y_test_float = y_test.astype(float)


# Predict the test data
y_pred = model.predict(X_test_float)

# Convert continuous output to categorical output
y_pred_cat = ['non-diabetic' if i < 5.7 else 'pre-diabetic' if i < 6.4 else 'diabetic' for i in y_pred]
y_test_cat = ['non-diabetic' if i < 5.7 else 'pre-diabetic' if i < 6.4 else 'diabetic' for i in y_test_float]

# Calculate the test accuracy
test_accuracy = accuracy_score(y_test_cat, y_pred_cat)
print(f"Test Accuracy: {test_accuracy}")

# Plot the confusion matrix
sns.heatmap(y_pred, cmap='coolwarm')
plt.xlabel('Predicted Class')
plt.ylabel('Actual Class')
plt.title('Confusion Matrix')
plt.show()

# Count the number of pre-diabetic, non-diabetic and diabetic patients
unique_elements, counts_elements = np.unique(y_pred_cat, return_counts=True)
print("Frequency of unique values of the said array:")
print(np.asarray((unique_elements, counts_elements)))